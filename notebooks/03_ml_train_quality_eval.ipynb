{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ML Quality Eval: Train Model (Simplified)\n",
        "Train on train set only - matches your SpeedAccelerationPredictor approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "# CELL 1: Parameters\n",
        "RUN_TIMESTAMP = \"2025-01-01_00-00-00\"\n",
        "INPUT_TRAIN_DATA = \"s3://models-quality-eval-ml/train/train_data.pkl\"\n",
        "OUTPUT_ML_MODEL_PATH = \"s3://models-quality-eval-ml/models/speed_accel_model.pkl\"\n",
        "\n",
        "# Use cross-validation for extra robustness? (slower but more stable)\n",
        "USE_CROSS_VALIDATION = False  # Set True if you have limited data\n",
        "\n",
        "MINIO_ENDPOINT = \"http://minio:9000\"\n",
        "MINIO_ACCESS_KEY = \"admin\"\n",
        "MINIO_SECRET_KEY = \"password123\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 2: Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import s3fs\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    HAS_XGB = True\n",
        "except:\n",
        "    HAS_XGB = False\n",
        "    print(\"‚ö†Ô∏è  XGBoost not available, will skip\")\n",
        "\n",
        "print(\"‚úÖ Libraries imported!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 3: MinIO Config\n",
        "fs = s3fs.S3FileSystem(\n",
        "    key=MINIO_ACCESS_KEY,\n",
        "    secret=MINIO_SECRET_KEY,\n",
        "    client_kwargs={'endpoint_url': MINIO_ENDPOINT}\n",
        ")\n",
        "\n",
        "storage_options = {\n",
        "    \"key\": MINIO_ACCESS_KEY,\n",
        "    \"secret\": MINIO_SECRET_KEY,\n",
        "    \"client_kwargs\": {\"endpoint_url\": MINIO_ENDPOINT}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 4: Load Training Data\n",
        "print(f\"=== ML Quality Eval: Training on Train Set ===\")\n",
        "print(f\"Run Timestamp: {RUN_TIMESTAMP}\")\n",
        "print(f\"\\nLoading training data from {INPUT_TRAIN_DATA}...\")\n",
        "\n",
        "try:\n",
        "    with fs.open(INPUT_TRAIN_DATA, 'rb') as f:\n",
        "        df = pickle.load(f)\n",
        "    \n",
        "    if isinstance(df, pd.DataFrame):\n",
        "        print(f\"‚úÖ Loaded DataFrame with {len(df):,} rows\")\n",
        "    else:\n",
        "        raise TypeError(f\"Expected DataFrame, got {type(df)}\")\n",
        "    \n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå Error: {INPUT_TRAIN_DATA} not found. Run step 01 first.\")\n",
        "    raise\n",
        "\n",
        "print(f\"Training dataset shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns[:15])}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 5: Column Normalization (YOUR WAY)\n",
        "print(\"\\nNormalizing column names...\")\n",
        "\n",
        "column_mapping = {\n",
        "    'timestamp_sensor': 'timestamp',\n",
        "    'latitude': 'position_lat',\n",
        "    'longitude': 'position_long',\n",
        "    'speed_ms': 'speed_mps',\n",
        "    'altitude': 'enhanced_altitude',\n",
        "    'acc_forward': 'acceleration_m_s2',\n",
        "    'acceleration': 'acceleration_m_s2'\n",
        "}\n",
        "\n",
        "for old, new in column_mapping.items():\n",
        "    if old in df.columns and new not in df.columns:\n",
        "        df.rename(columns={old: new}, inplace=True)\n",
        "\n",
        "print(\"‚úÖ Column normalization complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 6: Feature Engineering (EXACTLY YOUR WAY)\n",
        "print(\"\\nPerforming feature engineering...\")\n",
        "\n",
        "# Sort by trip and time\n",
        "if 'trip_id' in df.columns:\n",
        "    df = df.sort_values(['trip_id', 'seconds_elapsed'])\n",
        "else:\n",
        "    df = df.sort_values('seconds_elapsed')\n",
        "\n",
        "# Previous speed values\n",
        "if 'trip_id' in df.columns:\n",
        "    df['speed_mps_prev1'] = df.groupby('trip_id')['speed_mps'].shift(1).fillna(0)\n",
        "    df['speed_mps_prev2'] = df.groupby('trip_id')['speed_mps'].shift(2).fillna(0)\n",
        "else:\n",
        "    df['speed_mps_prev1'] = df['speed_mps'].shift(1).fillna(0)\n",
        "    df['speed_mps_prev2'] = df['speed_mps'].shift(2).fillna(0)\n",
        "\n",
        "# Delta features\n",
        "if 'position_lat' in df.columns and 'position_long' in df.columns:\n",
        "    if 'trip_id' in df.columns:\n",
        "        df['delta_lat'] = df.groupby('trip_id')['position_lat'].diff().fillna(0)\n",
        "        df['delta_lon'] = df.groupby('trip_id')['position_long'].diff().fillna(0)\n",
        "    else:\n",
        "        df['delta_lat'] = df['position_lat'].diff().fillna(0)\n",
        "        df['delta_lon'] = df['position_long'].diff().fillna(0)\n",
        "    df['delta_dist'] = np.sqrt(df['delta_lat']**2 + df['delta_lon']**2)\n",
        "else:\n",
        "    df['delta_lat'] = 0\n",
        "    df['delta_lon'] = 0\n",
        "    df['delta_dist'] = 0\n",
        "\n",
        "# Elevation gain\n",
        "if 'enhanced_altitude' in df.columns:\n",
        "    if 'trip_id' in df.columns:\n",
        "        df['elev_gain_m'] = df.groupby('trip_id')['enhanced_altitude'].diff().fillna(0)\n",
        "    else:\n",
        "        df['elev_gain_m'] = df['enhanced_altitude'].diff().fillna(0)\n",
        "else:\n",
        "    df['elev_gain_m'] = 0\n",
        "\n",
        "# Traffic level\n",
        "if 'label_traffic' in df.columns:\n",
        "    traffic_map = {'heavy': 2, 'moderate': 1, 'light': 0}\n",
        "    df['traffic_level'] = df['label_traffic'].map(traffic_map).fillna(1)\n",
        "else:\n",
        "    df['traffic_level'] = 1\n",
        "\n",
        "# Heading/bearing features\n",
        "if 'bearing' not in df.columns:\n",
        "    df['bearing'] = 0\n",
        "    \n",
        "if 'trip_id' in df.columns:\n",
        "    df['heading_change'] = df.groupby('trip_id')['bearing'].diff().fillna(0)\n",
        "else:\n",
        "    df['heading_change'] = df['bearing'].diff().fillna(0)\n",
        "\n",
        "# Turn count (sharp heading changes > 15 degrees)\n",
        "df['turn_count'] = (np.abs(df['heading_change']) > 15).astype(int)\n",
        "\n",
        "# Fill any remaining NaN values\n",
        "df = df.fillna(0)\n",
        "\n",
        "print(\"‚úÖ Feature engineering complete\")\n",
        "print(f\"   Dataset shape after features: {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 7: Prepare Training Data (YOUR FEATURES)\n",
        "feature_cols = [\n",
        "    'enhanced_altitude', 'bearing',\n",
        "    'speed_mps_prev1', 'speed_mps_prev2',\n",
        "    'delta_dist', 'delta_lat', 'delta_lon',\n",
        "    'elev_gain_m', 'traffic_level',\n",
        "    'heading_change', 'turn_count'\n",
        "]\n",
        "\n",
        "# Ensure all features exist\n",
        "missing = [c for c in feature_cols if c not in df.columns]\n",
        "if missing:\n",
        "    print(f\"‚ö†Ô∏è  Warning: Missing columns {missing}. Creating with zeros.\")\n",
        "    for col in missing:\n",
        "        df[col] = 0\n",
        "\n",
        "X = df[feature_cols].values\n",
        "y_speed = df['speed_mps'].values\n",
        "\n",
        "print(f\"\\n‚úÖ Training data prepared:\")\n",
        "print(f\"   X shape: {X.shape}\")\n",
        "print(f\"   y_speed shape: {y_speed.shape}\")\n",
        "print(f\"   Features: {feature_cols}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 8: Scale Features\n",
        "print(\"\\nScaling features...\")\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "print(\"‚úÖ Features scaled\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 9: Train-Val Split (for model selection)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled, y_speed, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"\\nTrain/Validation split:\")\n",
        "print(f\"   Training samples: {len(X_train):,}\")\n",
        "print(f\"   Validation samples: {len(X_val):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 10: Define Models (YOUR MODELS with FIXED hyperparameters)\n",
        "print(\"\\n=== Defining Models (Fixed Hyperparameters) ===\")\n",
        "\n",
        "# Use best hyperparameters from your production training\n",
        "# NO GridSearchCV - too expensive for weekly quality checks!\n",
        "models = {\n",
        "    'RandomForest': RandomForestRegressor(\n",
        "        n_estimators=300,\n",
        "        max_depth=20,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    'DecisionTree': DecisionTreeRegressor(\n",
        "        max_depth=20,\n",
        "        random_state=42\n",
        "    ),\n",
        "    'SVR': SVR(\n",
        "        C=10,\n",
        "        gamma='scale',\n",
        "        kernel='rbf'\n",
        "    ),\n",
        "    'ANN': MLPRegressor(\n",
        "        hidden_layer_sizes=(128, 64),\n",
        "        activation='relu',\n",
        "        max_iter=500,\n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "# Add XGBoost if available\n",
        "if HAS_XGB:\n",
        "    models['XGBoost'] = xgb.XGBRegressor(\n",
        "        n_estimators=200,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=6,\n",
        "        tree_method='hist',\n",
        "        eval_metric='rmse',\n",
        "        random_state=42\n",
        "    )\n",
        "    print(f\"‚úÖ {len(models)} models defined (including XGBoost)\")\n",
        "else:\n",
        "    print(f\"‚úÖ {len(models)} models defined (XGBoost skipped)\")\n",
        "\n",
        "for name in models.keys():\n",
        "    print(f\"   - {name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 11: Train Models\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚ö° TRAINING MODELS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "results = []\n",
        "trained_models = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"üöÄ Training: {name}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    \n",
        "    # Train on training set\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Predict on validation set\n",
        "    y_pred = model.predict(X_val)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    r2 = r2_score(y_val, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "    mae = mean_absolute_error(y_val, y_pred)\n",
        "    mse = mean_squared_error(y_val, y_pred)\n",
        "    \n",
        "    # Calculate MAPE (avoid divide by zero)\n",
        "    y_val_safe = np.where(y_val == 0, 1e-6, y_val)\n",
        "    mape = np.mean(np.abs((y_val - y_pred) / y_val_safe)) * 100\n",
        "    \n",
        "    print(f\"\\nüìä SPEED METRICS:\")\n",
        "    print(f\"  R¬≤   : {r2:.4f}\")\n",
        "    print(f\"  RMSE : {rmse:.4f} m/s ({rmse*3.6:.2f} km/h)\")\n",
        "    print(f\"  MAE  : {mae:.4f} m/s ({mae*3.6:.2f} km/h)\")\n",
        "    print(f\"  MSE  : {mse:.4f}\")\n",
        "    print(f\"  MAPE : {mape:.2f}%\")\n",
        "    \n",
        "    # Optional: Cross-validation for extra confidence\n",
        "    if USE_CROSS_VALIDATION:\n",
        "        print(f\"\\n  Running 5-fold CV...\")\n",
        "        cv_scores = cross_val_score(\n",
        "            model, X_scaled, y_speed,\n",
        "            cv=5,\n",
        "            scoring='neg_mean_squared_error',\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        cv_rmse = np.sqrt(-cv_scores.mean())\n",
        "        print(f\"  CV RMSE: {cv_rmse:.4f} ¬± {np.std(cv_scores):.4f}\")\n",
        "    \n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'R¬≤': r2,\n",
        "        'RMSE': rmse,\n",
        "        'MAE': mae,\n",
        "        'MSE': mse,\n",
        "        'MAPE': mape\n",
        "    })\n",
        "    \n",
        "    trained_models[name] = model\n",
        "\n",
        "# Create results DataFrame\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results = df_results.sort_values('RMSE').reset_index(drop=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìä MODEL COMPARISON (sorted by RMSE)\")\n",
        "print(\"=\"*70)\n",
        "print(df_results.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 12: Select Best Model (by RMSE, like your original)\n",
        "best_name = df_results.iloc[0]['Model']\n",
        "best_model = trained_models[best_name]\n",
        "best_r2 = df_results.iloc[0]['R¬≤']\n",
        "best_rmse = df_results.iloc[0]['RMSE']\n",
        "best_mae = df_results.iloc[0]['MAE']\n",
        "\n",
        "print(f\"\\nüèÜ BEST MODEL SELECTED\")\n",
        "print(f\"‚û° Model : {best_name}\")\n",
        "print(f\"‚û° R¬≤    : {best_r2:.4f}\")\n",
        "print(f\"‚û° RMSE  : {best_rmse:.4f} m/s ({best_rmse*3.6:.2f} km/h)\")\n",
        "print(f\"‚û° MAE   : {best_mae:.4f} m/s ({best_mae*3.6:.2f} km/h)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 13: Retrain Best Model on Full Training Set\n",
        "print(f\"\\nRetraining {best_name} on full training set...\")\n",
        "\n",
        "# Get fresh instance with same params\n",
        "final_model = models[best_name]\n",
        "final_model.fit(X_scaled, y_speed)\n",
        "\n",
        "print(\"‚úÖ Final model trained on all training data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 14: Save Model (YOUR ARTIFACT FORMAT)\n",
        "print(f\"\\nSaving model to {OUTPUT_ML_MODEL_PATH}...\")\n",
        "\n",
        "# Match YOUR artifact structure exactly\n",
        "artifact = {\n",
        "    \"scaler\": scaler,\n",
        "    \"speed_model\": final_model,\n",
        "    \"speed_model_name\": best_name,\n",
        "    \"feature_cols\": feature_cols,\n",
        "    \"train_metrics\": {\n",
        "        \"r2\": float(best_r2),\n",
        "        \"rmse\": float(best_rmse),\n",
        "        \"mae\": float(best_mae),\n",
        "        \"model_name\": best_name\n",
        "    }\n",
        "}\n",
        "\n",
        "with fs.open(OUTPUT_ML_MODEL_PATH, 'wb') as f:\n",
        "    pickle.dump(artifact, f)\n",
        "\n",
        "print(\"‚úÖ ML Model saved successfully\")\n",
        "print(f\"\\n\" + \"=\"*70)\n",
        "print(\"üéâ TRAINING COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Run Timestamp: {RUN_TIMESTAMP}\")\n",
        "print(f\"Best Model: {best_name}\")\n",
        "print(f\"Training R¬≤: {best_r2:.4f}\")\n",
        "print(f\"Training RMSE: {best_rmse:.4f} m/s ({best_rmse*3.6:.2f} km/h)\")\n",
        "print(f\"Training MAE: {best_mae:.4f} m/s ({best_mae*3.6:.2f} km/h)\")\n",
        "print(f\"Model saved to: {OUTPUT_ML_MODEL_PATH}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
