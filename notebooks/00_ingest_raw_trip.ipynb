{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "# @title 0. Ingest & Sensor Fusion (Zip Support)\n",
        "# CELL 1 [TAG: parameters]\n",
        "# Default parameters (Airflow will inject specific zip paths here)\n",
        "INPUT_ZIP_PATH = \"s3://raw-gps/trip01.zip\"\n",
        "OUTPUT_PROCESSED_PATH = \"s3://processed-data/trip01_1hz.csv\"\n",
        "GOOGLE_ROADS_API_KEY = \"YOUR_API_KEY_HERE\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 2: Imports\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import requests\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import s3fs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 3: MinIO Configuration & Helper Functions\n",
        "MINIO_ENDPOINT = os.environ.get(\"MINIO_ENDPOINT\", \"http://minio:9000\")\n",
        "MINIO_KEY = os.environ.get(\"MINIO_ACCESS_KEY\", \"admin\")\n",
        "MINIO_SECRET = os.environ.get(\"MINIO_SECRET_KEY\", \"password123\")\n",
        "\n",
        "# Initialize S3 Filesystem\n",
        "fs = s3fs.S3FileSystem(\n",
        "    key=MINIO_KEY,\n",
        "    secret=MINIO_SECRET,\n",
        "    client_kwargs={'endpoint_url': MINIO_ENDPOINT}\n",
        ")\n",
        "\n",
        "# Pandas storage options for saving later\n",
        "storage_options = {\n",
        "    \"key\": MINIO_KEY,\n",
        "    \"secret\": MINIO_SECRET,\n",
        "    \"client_kwargs\": {\"endpoint_url\": MINIO_ENDPOINT}\n",
        "}\n",
        "\n",
        "def snap_batch(latitudes, longitudes, api_key):\n",
        "    \"\"\"Calls Google Roads API for up to 100 points.\"\"\"\n",
        "    url = \"https://roads.googleapis.com/v1/snapToRoads\"\n",
        "    path_str = \"|\".join(f\"{lat},{lng}\" for lat, lng in zip(latitudes, longitudes))\n",
        "    params = {\"path\": path_str, \"key\": api_key, \"interpolate\": \"false\"}\n",
        "    for attempt in range(3):\n",
        "        resp = requests.get(url, params=params, timeout=10)\n",
        "        if resp.status_code == 200:\n",
        "            return resp.json().get(\"snappedPoints\", [])\n",
        "        time.sleep(1)\n",
        "    return []\n",
        "\n",
        "def assign_segment_ids(df, api_key):\n",
        "    if api_key == \"YOUR_API_KEY_HERE\":\n",
        "        df['segment_id'] = \"dummy_\" + (df.index // 60).astype(str)\n",
        "        return df\n",
        "\n",
        "    df_out = df.copy()\n",
        "    segment_ids = np.array([None] * len(df), dtype=object)\n",
        "\n",
        "    for start in range(0, len(df), 100):\n",
        "        end = min(start + 100, len(df))\n",
        "        batch = df.iloc[start:end]\n",
        "        snapped = snap_batch(batch['latitude'].tolist(), batch['longitude'].tolist(), api_key)\n",
        "        for pt in snapped:\n",
        "            if \"originalIndex\" in pt:\n",
        "                segment_ids[start + pt[\"originalIndex\"]] = pt[\"placeId\"]\n",
        "\n",
        "    df_out['segment_id'] = segment_ids\n",
        "    df_out['segment_id'] = df_out['segment_id'].ffill().bfill()\n",
        "    return df_out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 4: Load Raw Data from Zip (S3)\n",
        "print(f\"Extracting data from {INPUT_ZIP_PATH}...\")\n",
        "try:\n",
        "    with fs.open(INPUT_ZIP_PATH, 'rb') as f:\n",
        "        with zipfile.ZipFile(f) as z:\n",
        "            with z.open('Accelerometer.csv') as acc_file:\n",
        "                acc = pd.read_csv(acc_file)\n",
        "            with z.open('Orientation.csv') as ori_file:\n",
        "                ori = pd.read_csv(ori_file)\n",
        "            with z.open('Location.csv') as loc_file:\n",
        "                loc = pd.read_csv(loc_file)\n",
        "    print(\"✅ CSVs loaded successfully from Zip.\")\n",
        "except Exception as exc:  # pylint: disable=broad-except\n",
        "    print(f\"⚠️ Error reading zip ({exc}). Using synthetic data...\")\n",
        "    t = np.linspace(0, 600, 60000)\n",
        "    acc = pd.DataFrame({'time': t, 'seconds_elapsed': t, 'x': 0, 'y': 0, 'z': 9.8})\n",
        "    ori = pd.DataFrame({'time': t, 'seconds_elapsed': t, 'qx': 0, 'qy': 0, 'qz': 0, 'qw': 1})\n",
        "    loc = pd.DataFrame({\n",
        "        'time': np.linspace(0, 600, 600),\n",
        "        'seconds_elapsed': np.linspace(0, 600, 600),\n",
        "        'latitude': 0,\n",
        "        'longitude': 0,\n",
        "        'speed': 10,\n",
        "        'bearing': 0,\n",
        "        'altitude': 0\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 5: Sensor Fusion (Standard Logic)\n",
        "t_master = acc['seconds_elapsed'].values\n",
        "t_dt = pd.to_datetime(acc['time'], unit='ns')\n",
        "\n",
        "# Interpolate Orientation\n",
        "qx = np.interp(t_master, ori['seconds_elapsed'], ori.get('qx', ori.get('x')))\n",
        "qy = np.interp(t_master, ori['seconds_elapsed'], ori.get('qy', ori.get('y')))\n",
        "qz = np.interp(t_master, ori['seconds_elapsed'], ori.get('qz', ori.get('z')))\n",
        "qw = np.interp(t_master, ori['seconds_elapsed'], ori.get('qw', ori.get('w')))\n",
        "q_norm = np.sqrt(qx**2 + qy**2 + qz**2 + qw**2)\n",
        "qx, qy, qz, qw = qx / q_norm, qy / q_norm, qz / q_norm, qw / q_norm\n",
        "\n",
        "# Rotate Acceleration\n",
        "a_dev = acc[['x', 'y', 'z']].values\n",
        "q_vec = np.stack([qx, qy, qz], axis=1)\n",
        "w = qw\n",
        "t_vec = 2 * np.cross(q_vec, a_dev)\n",
        "a_world = a_dev + (w[:, None] * t_vec) + np.cross(q_vec, t_vec)\n",
        "\n",
        "# Interpolate GPS & Calculate Forward Acc\n",
        "gps_interp = {}\n",
        "for col in ['speed', 'bearing', 'latitude', 'longitude']:\n",
        "    gps_interp[col] = np.interp(t_master, loc['seconds_elapsed'], loc[col])\n",
        "\n",
        "bearing_rad = np.deg2rad(gps_interp['bearing'])\n",
        "acc_forward = a_world[:, 0] * np.sin(bearing_rad) + a_world[:, 1] * np.cos(bearing_rad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 6: Resample & Process\n",
        "df_hr = pd.DataFrame({\n",
        "    't': t_dt,\n",
        "    'seconds_elapsed': t_master,\n",
        "    'speed_kmh': gps_interp['speed'] * 3.6,\n",
        "    'acc_forward': acc_forward,\n",
        "    'latitude': gps_interp['latitude'],\n",
        "    'longitude': gps_interp['longitude']\n",
        "})\n",
        "\n",
        "df_1Hz = df_hr.set_index('t').resample('1S').median().dropna().reset_index()\n",
        "print(\"Running Snap-to-Roads...\")\n",
        "# df_final = assign_segment_ids(df_1Hz, GOOGLE_ROADS_API_KEY)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 7: Save to S3\n",
        "print(f\"Saving to {OUTPUT_PROCESSED_PATH}...\")\n",
        "df_final.to_csv(OUTPUT_PROCESSED_PATH, index=False, storage_options=storage_options)\n",
        "print(\"✅ Done.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
