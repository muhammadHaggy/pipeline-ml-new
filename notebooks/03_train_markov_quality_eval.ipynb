{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Train Markov Models (Quality Eval - Train Set Only)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "# @title 3. Train Markov Models (Quality Eval)\n",
        "\n",
        "# CELL 1 [TAG: parameters]\n",
        "# ---------------------------------------------------------\n",
        "# Default parameters (Airflow will OVERWRITE these)\n",
        "# ---------------------------------------------------------\n",
        "RUN_TIMESTAMP = \"2025-01-01_00-00-00\"  # Injected by Airflow\n",
        "INPUT_GROUPED_DATA = \"s3://models-quality-eval/2025-01-01_00-00-00/train/grouped_segments.pkl\"\n",
        "OUTPUT_MODEL_DIR = \"s3://models-quality-eval/2025-01-01_00-00-00/models/\"\n",
        "V_RES = 2.5\n",
        "A_RES = 0.25\n",
        "\n",
        "# MinIO Credentials (DEFAULTS ONLY - Airflow injects real ones)\n",
        "MINIO_ENDPOINT = \"http://localhost:9000\"\n",
        "MINIO_ACCESS_KEY = \"admin\"\n",
        "MINIO_SECRET_KEY = \"password123\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 2: Imports\n",
        "import pickle\n",
        "import numpy as np\n",
        "import s3fs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 3: MinIO Configuration\n",
        "# Initialize S3 Filesystem\n",
        "fs = s3fs.S3FileSystem(\n",
        "    key=MINIO_ACCESS_KEY,\n",
        "    secret=MINIO_SECRET_KEY,\n",
        "    client_kwargs={'endpoint_url': MINIO_ENDPOINT}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 4: Logic\n",
        "print(f\"Loading TRAIN grouped segments from {INPUT_GROUPED_DATA}...\")\n",
        "print(f\"Run Timestamp: {RUN_TIMESTAMP}\")\n",
        "try:\n",
        "    with fs.open(INPUT_GROUPED_DATA, 'rb') as f:\n",
        "        grouped_segments = pickle.load(f)\n",
        "    print(\"✅ Training data loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"❌ Error: Input file {INPUT_GROUPED_DATA} not found. Run Step 01 first.\")\n",
        "    raise\n",
        "\n",
        "transition_matrices = []\n",
        "state_definitions = []\n",
        "\n",
        "for group_idx in range(2):\n",
        "    # Check if group has data\n",
        "    if len(grouped_segments[group_idx]) == 0:\n",
        "        print(f\"Warning: Group {group_idx} is empty. Skipping model training for this group.\")\n",
        "        transition_matrices.append(None)\n",
        "        state_definitions.append(None)\n",
        "        continue\n",
        "\n",
        "    all_data = np.concatenate(grouped_segments[group_idx])\n",
        "\n",
        "    # [cite_start]Grid Definitions [cite: 256]\n",
        "    v_bins = np.arange(0, np.max(all_data[:, 0]) + V_RES, V_RES)\n",
        "    a_bins = np.arange(np.min(all_data[:, 1]), np.max(all_data[:, 1]) + A_RES, A_RES)\n",
        "    num_a_bins = len(a_bins)\n",
        "\n",
        "    # [cite_start]State Mapping [cite: 258]\n",
        "    v_indices = np.digitize(all_data[:, 0], v_bins) - 1\n",
        "    a_indices = np.digitize(all_data[:, 1], a_bins) - 1\n",
        "    states = v_indices * num_a_bins + a_indices\n",
        "    unique_states = np.unique(states)\n",
        "    state_map = {id: i for i, id in enumerate(unique_states)}\n",
        "    n_states = len(unique_states)\n",
        "\n",
        "    # [cite_start]Build Matrix [cite: 248]\n",
        "    trans_matrix = np.zeros((n_states, n_states))\n",
        "    for i in range(len(states) - 1):\n",
        "        if states[i] in state_map and states[i + 1] in state_map:\n",
        "            trans_matrix[state_map[states[i]], state_map[states[i + 1]]] += 1\n",
        "\n",
        "    # Normalize to Probabilities\n",
        "    row_sums = trans_matrix.sum(axis=1, keepdims=True)\n",
        "    # Avoid division by zero for dead-end states\n",
        "    trans_matrix = np.divide(trans_matrix, row_sums, out=np.zeros_like(trans_matrix), where=row_sums != 0)\n",
        "\n",
        "    # Build Lookup Table (State ID -> Physical Values)\n",
        "    state_lookup = np.zeros((n_states, 2))\n",
        "    for real_id, matrix_idx in state_map.items():\n",
        "        v_idx, a_idx = divmod(real_id, num_a_bins)\n",
        "        if v_idx < len(v_bins):\n",
        "            state_lookup[matrix_idx, 0] = v_bins[v_idx] + V_RES / 2\n",
        "        # We store accel too, though currently only speed is used for reconstruction\n",
        "        if a_idx < len(a_bins):\n",
        "            state_lookup[matrix_idx, 1] = a_bins[a_idx] + A_RES / 2\n",
        "\n",
        "    transition_matrices.append(trans_matrix)\n",
        "    state_definitions.append(state_lookup)\n",
        "    print(f\"Group {group_idx} Model Trained: {n_states} unique states found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 5: Visualization (Speed-Acceleration Grid Map)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mapping index to names as requested\n",
        "group_labels = {0: \"Heavy Traffic\", 1: \"Light Traffic\"}\n",
        "\n",
        "for group_idx in range(2):\n",
        "    # Skip if no model was trained for this group\n",
        "    if group_idx >= len(state_definitions) or state_definitions[group_idx] is None:\n",
        "        print(f\"Skipping visualization for Group {group_idx} (No model found).\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Generating S-A Grid Map for {group_labels[group_idx]}...\")\n",
        "\n",
        "    # 1. Retrieve Data\n",
        "    # Get the raw data points used for this group\n",
        "    raw_points = np.concatenate(grouped_segments[group_idx])\n",
        "    # Get the lookup table (State ID -> [Speed Center, Accel Center])\n",
        "    lookup_table = state_definitions[group_idx]\n",
        "\n",
        "    # 2. Setup Plot\n",
        "    fig, ax = plt.subplots(figsize=(14, 9))\n",
        "\n",
        "    # 3. Plot Raw S-A Grid Values (Hollow Blue Circles)\n",
        "    # edgecolors='b', facecolors='none' creates the hollow circle effect\n",
        "    ax.scatter(raw_points[:, 0], raw_points[:, 1],\n",
        "               s=30, alpha=0.6, edgecolors='dodgerblue', facecolors='none', \n",
        "               label='S-A Grid Values')\n",
        "\n",
        "    # 4. Plot State IDs (Red Text)\n",
        "    # We iterate through the lookup table to place the ID at the bin center\n",
        "    for state_id, coords in enumerate(lookup_table):\n",
        "        v_center = coords[0]\n",
        "        a_center = coords[1]\n",
        "        \n",
        "        # Only plot text if it's within the visible graph limits (optional check)\n",
        "        ax.text(v_center, a_center, str(state_id),\n",
        "                color='darkred', fontsize=9, fontweight='bold', \n",
        "                ha='center', va='center', label='States' if state_id == 0 else \"\")\n",
        "\n",
        "    # 5. Configure Grid Lines (To match V_RES and A_RES)\n",
        "    # Determine bounds for the grid\n",
        "    v_max_plot = np.max(raw_points[:, 0]) + V_RES\n",
        "    a_min_plot = np.min(raw_points[:, 1]) - A_RES\n",
        "    a_max_plot = np.max(raw_points[:, 1]) + A_RES\n",
        "\n",
        "    # Set ticks to align exactly with the resolution (bin edges)\n",
        "    # We shift by half resolution because the lookup table stores centers, \n",
        "    # but the grid lines should be on the edges.\n",
        "    x_ticks = np.arange(0, v_max_plot, V_RES)\n",
        "    y_ticks = np.arange(np.floor(a_min_plot), np.ceil(a_max_plot), A_RES)\n",
        "\n",
        "    ax.set_xticks(x_ticks)\n",
        "    ax.set_yticks(y_ticks)\n",
        "    ax.grid(True, which='both', linestyle='-', color='gray', alpha=0.5)\n",
        "\n",
        "    # 6. Labels and Titles\n",
        "    ax.set_xlabel(\"Speed (km/h)\", fontsize=14)\n",
        "    ax.set_ylabel(\"Acceleration ($m/s^2$)\", fontsize=14)\n",
        "    ax.set_title(f\"Speed-Acceleration Grid Map: {group_labels[group_idx]} (SEG{group_idx})\", fontsize=16)\n",
        "    \n",
        "    # Custom Legend\n",
        "    # Since we plotted text multiple times, we need to handle the legend manually \n",
        "    # or rely on the label set in the first iteration.\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    # Filter duplicates in legend caused by the text loop\n",
        "    by_label = dict(zip(labels, handles))\n",
        "    ax.legend(by_label.values(), by_label.keys(), loc='upper right', framealpha=1, fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 5: Save\n",
        "# Ensure output path ends with slash for cleanliness, though S3 is object store\n",
        "model_dir = OUTPUT_MODEL_DIR.rstrip(\"/\")\n",
        "print(f\"Saving models to {model_dir}...\")\n",
        "\n",
        "# Save Transition Matrices\n",
        "with fs.open(f\"{model_dir}/transition_matrices.pkl\", 'wb') as f:\n",
        "    pickle.dump(transition_matrices, f)\n",
        "\n",
        "# Save State Definitions\n",
        "with fs.open(f\"{model_dir}/state_definitions.pkl\", 'wb') as f:\n",
        "    pickle.dump(state_definitions, f)\n",
        "\n",
        "print(\"✅ Markov Models saved to MinIO (Quality Eval).\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
