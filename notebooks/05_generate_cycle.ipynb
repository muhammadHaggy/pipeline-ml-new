{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. Generate Continuous Cycle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "# CELL 1 [TAG: parameters]\n",
        "# ---------------------------------------------------------\n",
        "# Default parameters (Airflow will OVERWRITE these)\n",
        "# ---------------------------------------------------------\n",
        "INPUT_TOPOLOGY_PATH = \"s3://runs/test_run/topology.json\"\n",
        "MODEL_DIR = \"s3://models/prod/\"\n",
        "REF_SEGMENTS_PATH = \"s3://models/reference_segments.pkl\"\n",
        "OUTPUT_CYCLE_PATH = \"s3://runs/test_run/cycle.csv\"\n",
        "\n",
        "# MinIO Credentials (DEFAULTS ONLY)\n",
        "MINIO_ENDPOINT = \"http://localhost:9000\"\n",
        "MINIO_ACCESS_KEY = \"admin\"\n",
        "MINIO_SECRET_KEY = \"password123\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 2: Imports\n",
        "import pickle\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import s3fs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 3: MinIO Configuration\n",
        "# Initialize S3 Filesystem\n",
        "fs = s3fs.S3FileSystem(\n",
        "    key=MINIO_ACCESS_KEY,\n",
        "    secret=MINIO_SECRET_KEY,\n",
        "    client_kwargs={'endpoint_url': MINIO_ENDPOINT}\n",
        ")\n",
        "\n",
        "# Pandas storage options for saving CSV later\n",
        "storage_options = {\n",
        "    \"key\": MINIO_ACCESS_KEY,\n",
        "    \"secret\": MINIO_SECRET_KEY,\n",
        "    \"client_kwargs\": {\"endpoint_url\": MINIO_ENDPOINT}\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 4: Load Models & Topology\n",
        "print(\"Loading artifacts from MinIO...\")\n",
        "\n",
        "# Ensure directory path format\n",
        "model_base = MODEL_DIR.rstrip(\"/\")\n",
        "\n",
        "try:\n",
        "    # 1. Load Transition Matrices\n",
        "    with fs.open(f\"{model_base}/transition_matrices.pkl\", 'rb') as f:\n",
        "        trans_matrices = pickle.load(f)\n",
        "\n",
        "    # 2. Load State Definitions\n",
        "    with fs.open(f\"{model_base}/state_definitions.pkl\", 'rb') as f:\n",
        "        state_defs = pickle.load(f)\n",
        "\n",
        "    # 3. Load Reference Segments\n",
        "    with fs.open(REF_SEGMENTS_PATH, 'rb') as f:\n",
        "        ref_segments = pickle.load(f)\n",
        "\n",
        "    # 4. Load Topology (JSON)\n",
        "    with fs.open(INPUT_TOPOLOGY_PATH, 'r') as f:\n",
        "        topology = json.load(f)\n",
        "\n",
        "    print(\"✅ All artifacts loaded successfully.\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"❌ Missing Artifact: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 5: Logic (Continuous Generation)\n",
        "\n",
        "def generate_segment(duration, start_speed, matrix, states):\n",
        "    # Find state index closest to the required start_speed\n",
        "    start_node = np.argmin(np.abs(states[:, 0] - start_speed))\n",
        "    \n",
        "    current = start_node\n",
        "    path = [current]\n",
        "    \n",
        "    for _ in range(duration - 1):\n",
        "        probs = matrix[current]\n",
        "        if np.sum(probs) == 0:\n",
        "            next_state = current\n",
        "        else:\n",
        "            next_state = np.random.choice(len(probs), p=probs)\n",
        "        \n",
        "        path.append(next_state)\n",
        "        current = next_state\n",
        "        \n",
        "    return states[path, 0]\n",
        "\n",
        "final_cycle = []\n",
        "handoff_speed = 0.0\n",
        "\n",
        "print(f\"Generating cycle for {len(topology)} topology blocks...\")\n",
        "\n",
        "for i, block in enumerate(topology):\n",
        "    # 1. Determine Requested Group (0=Heavy, 1=Light)\n",
        "    is_heavy = block['condition'] in ['SLOW', 'TRAFFIC_JAM']\n",
        "    idx = 0 if is_heavy else 1\n",
        "    \n",
        "    # 2. Safety Check & Fallback\n",
        "    # If the model for the requested group is missing (None), try the other group.\n",
        "    if ref_segments[idx] is None or trans_matrices[idx] is None:\n",
        "        original_idx = idx\n",
        "        idx = 1 - idx # Toggle 0 -> 1 or 1 -> 0\n",
        "        \n",
        "        print(f\"⚠️ Warning (Block {i}): Model for Group {original_idx} is missing.\")\n",
        "        \n",
        "        if ref_segments[idx] is None:\n",
        "            raise ValueError(\"❌ Critical Error: No models found for EITHER Heavy or Light traffic. Please check your Training Pipeline (Step 01/02).\")\n",
        "            \n",
        "        print(f\"   > Fallback: Using Group {idx} model instead.\")\n",
        "\n",
        "    # 3. Estimate Duration\n",
        "    # Time = Distance / Average_Speed_of_Reference\n",
        "    avg_speed_ms = np.mean(ref_segments[idx][:, 0]) / 3.6\n",
        "    if avg_speed_ms < 1.0: avg_speed_ms = 1.0\n",
        "    \n",
        "    duration = int(block['length_m'] / avg_speed_ms)\n",
        "    if duration < 5: duration = 5\n",
        "    \n",
        "    # 4. Generate\n",
        "    segment = generate_segment(duration, handoff_speed, trans_matrices[idx], state_defs[idx])\n",
        "    final_cycle.append(segment)\n",
        "    \n",
        "    handoff_speed = segment[-1]\n",
        "\n",
        "# Stitch together\n",
        "if final_cycle:\n",
        "    final_speed_kmh = np.concatenate(final_cycle)\n",
        "else:\n",
        "    print(\"Warning: Empty cycle generated.\")\n",
        "    final_speed_kmh = np.array([])\n",
        "\n",
        "print(f\"Cycle construction complete. Total duration: {len(final_speed_kmh)}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 6: Save Output\n",
        "print(f\"Saving generated cycle ({len(final_speed_kmh)} seconds) to {OUTPUT_CYCLE_PATH}...\")\n",
        "df = pd.DataFrame({'speed_kmh': final_speed_kmh})\n",
        "df.to_csv(\n",
        "    OUTPUT_CYCLE_PATH,\n",
        "    index=False,\n",
        "    storage_options=storage_options\n",
        ")\n",
        "print(\"✅ Cycle saved.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
